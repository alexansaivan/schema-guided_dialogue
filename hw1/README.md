# Schema-Guided Dialogue (SGD) Dataset

## Overview

**Domain:** The Schema-Guided Dialogue (SGD) dataset consists of over 20k annotated multi-domain, task-oriented conversations between a human and a virtual assistant. The dialogues involve interactions with services and APIs spanning 20 domains, such as banks, events, media, calendar, travel, and weather.

## Download Source

- To obtain the **training set** dataset, I downloaded it from [dstc8-schema-guided-dialogue/train](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/train).
- Last Update: 10/19/2021

## Data Collection

The dialogues were generated with the help of a dialogue simulator and paid crowd-workers. More specifically, the dataset was collected using a simulation-based dialogue generation framework. The framework interacted with 45 synthetic implementations of services or APIs across 20 domains. The schema for each service was defined, including intents and slots with additional constraints. Real-world entities were sampled from Freebase to populate the slots, and some slots were synthetically sampled. The dialogue outlines generated by the framework were then paraphrased into natural language utterances by crowd-workers. This process preserved all annotations obtained from the simulator and did not require any additional annotations after dialogue collection.

## Designed for

The dataset is designed for developing large-scale virtual assistants. It can be used for tasks such as intent prediction, slot filling, dialogue state tracking, policy imitation learning, language generation, and user simulation learning.

## Annotation Information

The dataset contains annotations for active intents and dialogue states for each user utterance, as well as system actions for every system utterance. Additionally, there are annotations for user actions, although these are withheld from the public release. The dataset also includes schemas that provide semantic information about APIs and constituent intents and slots. These annotations enable the dataset to be used as a benchmark for various tasks such as intent detection, slot filling, dialogue state tracking, and dialogue act to text generation.

#### Obtaining the Annotations

The annotations in the dataset were obtained through a simulation-based data collection approach. This approach involved generating dialogues using a dialogue simulation framework and then sending them to crowd-workers. Then, the crowd-workers were instructed to paraphrase the utterances in the dialogues to ensure naturalness and coherence. The slot values in the paraphrases were required to be exactly repeated, which helped verify the correctness of the paraphrases and allowed for automatic slot span generation in the generated utterances. This procedure preserved all other annotations obtained from the simulator, eliminating the need for further annotation.

## Data Format

The dataset is stored in JSON format. Dialogues are represented as a list of turns, where each turn contains a user or system utterance. Dialogues are annotated with frames, each corresponding to a single service.

## License

The SGD and SGD-X datasets are released under the [Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/blob/master/LICENSE.txt) (more information about the **CC BY-SA 4.0** license [here](https://creativecommons.org/licenses/by-sa/4.0/)).

## Measurements

The Schema-Guided Dialogue training set contains 16142 multi-turn dialogues. The resulting metrics are given below.

### Total Data Length for User and System
- **Total Dialogues: 16142 dialogues**
- Total Turns: 329964 turns
- Total Sentences: 568891 sentences
- Total Words: 15011509 words
<br><br/>
- Total User Turns: 164982 turns
- Total User Sentences: 298963 sentences
- Total User Words: 7885477 words
<br><br/>
- Total System Turns: 164982 turns
- Total System Sentences: 269928 sentences
- Total System Words: 7126032 words
<br><br/>

### Mean Dialogue Lengths for User and System
- Average Total Turns: 20.44 turns per dialogue
- Average Tokens Per Turn: 45.49 tokens per turn
- Average Total Sentences: 35.24 sentences per dialogue
- Average Total Words: 929.97 words per dialogue
<br><br/>
- Average User Turns: 10.22 turns per dialogue
- Average User Sentences: 18.52 sentences per dialogue
- Average User Words: 488.51 words per dialogue
<br><br/>
- Average System Turns: 10.22 turns per dialogue
- Average System Sentences: 16.72 sentences per dialogue
- Average System Words: 441.46 words per dialogue
  <br><br/>
  
### Standard Deviations of Dialogue Lengths for User and System
- Standard Deviation Total Turns: 3.44 turns per dialogue
- Standard Deviation Total Sentences: 10.51 sentences per dialogue
- Standard Deviation Total Words: 325.48 words per dialogue
  <br><br/>
- Standard Deviation User Turns: 3.44 turns per dialogue
- Standard Deviation User Sentences: 1.22 sentences per dialogue
- Standard Deviation User Words: 26.33 words per dialogue
  <br><br/>
- Standard Deviation System Turns: 3.44 turns per dialogue
- Standard Deviation System Sentences: 0.95 sentences per dialogue
- Standard Deviation System Words: 22.22 words per dialogue
  <br><br/>
  
### Vocabulary Size
- User Vocabulary Size: 16909 words
- System Vocabulary Size: 16415 words
- Total Vocabulary Size: 21991 words

## Impressions on the Data

The dataset appears to be generated using a dialogue simulation framework and then paraphrased by crowd-workers to enhance naturalness. Conversations cover various domains, both single-domain and multi-domain, comprising a sizable set of over 16,000 dialogues with annotations for intents, dialogue states, and system actions.

**Difficulty of Learning:** Learning from this dataset might pose challenges due to diverse dialogue flows, numerous domains, slots, and slot values. However, it serves as a benchmark for tasks such as intent detection, dialogue state tracking, and dialogue act-to-text generation. This contributes to the development of scalable modeling approaches for virtual assistants.

**Usability in an Actual System:** The dataset is designed for seamless integration of new services and APIs with large-scale virtual assistants, offering a schema-guided paradigm for easy service integration. It's important to note the absence of annotations for user actions, potentially limiting its usability in certain applications.

**Limitations of the Data:** A limitation of the dataset lies in its generation using a dialogue simulation framework, possibly resulting in conversations that are less natural compared to other approaches like Wizard-of-Oz. Additionally, it does not expose the complete set of possible slot values, potentially impacting model performance on unseen services. The dataset, however, addresses these limitations by providing a cost-effective and error-resistant data collection approach.