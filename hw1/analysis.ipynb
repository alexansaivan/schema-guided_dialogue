{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_json_files(input_folder, output_file):\n",
    "    all_dialogues = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                dialogues = json.load(file)\n",
    "                all_dialogues.extend(dialogues)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        json.dump(all_dialogues, outfile, indent=2)\n",
    "\n",
    "input_folder = \"train\"\n",
    "output_file = \"dialogues.json\"\n",
    "merge_json_files(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_user_system_turns(dialogue):\n",
    "    turns = dialogue.get(\"turns\", [])\n",
    "\n",
    "    user_turns = [turn[\"utterance\"] for turn in turns if turn[\"speaker\"] == \"USER\"]\n",
    "    system_turns = [turn[\"utterance\"] for turn in turns if turn[\"speaker\"] == \"SYSTEM\"]\n",
    "\n",
    "    return user_turns, system_turns\n",
    "\n",
    "def print_user_system_turns(dialogue):\n",
    "    dialogue_id = dialogue.get(\"dialogue_id\", \"N/A\")\n",
    "\n",
    "    if dialogue_id is None or not re.match(r'\\d+_\\d+', dialogue_id):\n",
    "        return\n",
    "\n",
    "    services = dialogue.get(\"services\", [])\n",
    "    print(f\"\\nDialogue ID: {dialogue_id}\")\n",
    "    print(f\"Services: {', '.join(services)}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    user_turns, system_turns = split_user_system_turns(dialogue)\n",
    "\n",
    "    for user_turn, system_turn in zip(user_turns, system_turns):\n",
    "        print(f\"User Turn: {user_turn}\")\n",
    "        print(f\"System Turn: {system_turn}\")\n",
    "        print(\"-\" * 130)\n",
    "\n",
    "\n",
    "with open(\"dialogues_info.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    sys.stdout = output_file\n",
    "\n",
    "    with open(\"dialogues.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        dialogues_data = json.load(file)\n",
    "\n",
    "    for dialogue in dialogues_data:\n",
    "        print_user_system_turns(dialogue)\n",
    "\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total data length for user and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dialogues: 16142 dialogues\n",
      "Total turns: 329964 turns\n",
      "Total sentences: 568891 sentences\n",
      "Total words: 15011509 words\n",
      "\n",
      "Total user turns: 164982 turns\n",
      "Total user sentences: 298963 sentences\n",
      "Total user words: 7885477 words\n",
      "\n",
      "Total system turns: 164982 turns\n",
      "Total system sentences: 269928 sentences\n",
      "Total system words: 7126032 words\n"
     ]
    }
   ],
   "source": [
    "def count_metrics(dialogues):\n",
    "    total_dialogues = len(dialogues)\n",
    "    total_turns = 0\n",
    "    total_sentences = 0\n",
    "    total_words = 0\n",
    "    total_user_turns = 0\n",
    "    total_user_sentences = 0\n",
    "    total_user_words = 0\n",
    "    total_system_turns = 0\n",
    "    total_system_sentences = 0\n",
    "    total_system_words = 0\n",
    "    \n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        user_turns = dialogue.count(\"User Turn:\")\n",
    "        system_turns = dialogue.count(\"System Turn:\")\n",
    "        turns_in_dialogue = user_turns + system_turns\n",
    "\n",
    "        total_turns += turns_in_dialogue\n",
    "        total_user_turns += user_turns\n",
    "        total_system_turns += system_turns\n",
    "\n",
    "        turns = dialogue.split(\"User Turn:\")\n",
    "\n",
    "        user_turns_list = turns[1::2]\n",
    "        system_turns_list = turns[2::2]\n",
    "\n",
    "        for user_turn in user_turns_list:\n",
    "            sentences = len(sent_tokenize(user_turn))\n",
    "            words = len(word_tokenize(user_turn))\n",
    "            \n",
    "            total_user_sentences += sentences\n",
    "            total_user_words += words\n",
    "            total_sentences += sentences\n",
    "            total_words += words\n",
    "\n",
    "        for system_turn in system_turns_list:\n",
    "            sentences = len(sent_tokenize(system_turn))\n",
    "            words = len(word_tokenize(system_turn))\n",
    "            \n",
    "            total_system_sentences += sentences\n",
    "            total_system_words += words\n",
    "            total_sentences += sentences\n",
    "            total_words += words\n",
    "\n",
    "    return (\n",
    "        total_dialogues,\n",
    "        total_turns,\n",
    "        total_sentences,\n",
    "        total_words,\n",
    "        total_user_turns,\n",
    "        total_user_sentences,\n",
    "        total_user_words,\n",
    "        total_system_turns,\n",
    "        total_system_sentences,\n",
    "        total_system_words\n",
    "    )\n",
    "\n",
    "with open(\"dialogues_info.txt\", \"r\") as file:\n",
    "    dialogues_info = file.read()\n",
    "\n",
    "dialogues = dialogues_info.split(\"Dialogue ID:\")[1:]\n",
    "\n",
    "(\n",
    "    total_dialogues,\n",
    "    total_turns,\n",
    "    total_sentences,\n",
    "    total_words,\n",
    "    total_user_turns,\n",
    "    total_user_sentences,\n",
    "    total_user_words,\n",
    "    total_system_turns,\n",
    "    total_system_sentences,\n",
    "    total_system_words\n",
    ") = count_metrics(dialogues)\n",
    "\n",
    "print(f\"Total dialogues: {total_dialogues} dialogues\")\n",
    "print(f\"Total turns: {total_turns} turns\")\n",
    "print(f\"Total sentences: {total_sentences} sentences\")\n",
    "print(f\"Total words: {total_words} words\\n\")\n",
    "print(f\"Total user turns: {total_user_turns} turns\")\n",
    "print(f\"Total user sentences: {total_user_sentences} sentences\")\n",
    "print(f\"Total user words: {total_user_words} words\\n\")\n",
    "print(f\"Total system turns: {total_system_turns} turns\")\n",
    "print(f\"Total system sentences: {total_system_sentences} sentences\")\n",
    "print(f\"Total system words: {total_system_words} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean dialogue lengths for user and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total turns: 20.44 turns per dialogue\n",
      "Average tokens per turn: 45.49 tokens per turn\n",
      "Average total sentences: 35.24 sentences per dialogue\n",
      "Average total words: 929.97 words per dialogue\n",
      "\n",
      "Average user turns: 10.22 turns per dialogue for user interactions\n",
      "Average user sentences: 18.52 sentences per dialogue for user interactions\n",
      "Average user words: 488.51 words per dialogue for user interactions\n",
      "\n",
      "Average system turns: 10.22 turns per dialogue for system interactions\n",
      "Average system sentences: 16.72 sentences per dialogue for system interactions\n",
      "Average system words: 441.46 words per dialogue for system interactions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_total_turns = round(total_turns / total_dialogues, 2)\n",
    "average_tokens_per_turn = round(total_words / total_turns, 2)\n",
    "average_total_sentences = round(total_sentences / total_dialogues, 2)\n",
    "average_total_words = round(total_words / total_dialogues, 2)\n",
    "\n",
    "average_user_turns = round(total_user_turns / total_dialogues, 2)\n",
    "average_user_sentences = round(total_user_sentences / total_dialogues, 2)\n",
    "average_user_words = round(total_user_words / total_dialogues, 2)\n",
    "\n",
    "average_system_turns = round(total_system_turns / total_dialogues, 2)\n",
    "average_system_sentences = round(total_system_sentences / total_dialogues, 2)\n",
    "average_system_words = round(total_system_words / total_dialogues, 2)\n",
    "\n",
    "print(f\"Average total turns: {average_total_turns} turns per dialogue\")\n",
    "print(f\"Average tokens per turn: {average_tokens_per_turn} tokens per turn\")\n",
    "print(f\"Average total sentences: {average_total_sentences} sentences per dialogue\")\n",
    "print(f\"Average total words: {average_total_words} words per dialogue\\n\")\n",
    "print(f\"Average user turns: {average_user_turns} turns per dialogue for user interactions\")\n",
    "print(f\"Average user sentences: {average_user_sentences} sentences per dialogue for user interactions\")\n",
    "print(f\"Average user words: {average_user_words} words per dialogue for user interactions\\n\")\n",
    "print(f\"Average system turns: {average_system_turns} turns per dialogue for system interactions\")\n",
    "print(f\"Average system sentences: {average_system_sentences} sentences per dialogue for system interactions\")\n",
    "print(f\"Average system words: {average_system_words} words per dialogue for system interactions\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation of dialogue lengths for user and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation total turns: 3.44 turns per dialogue\n",
      "Standard deviation total sentences: 10.51 sentences per dialogue\n",
      "Standard deviation total words: 325.48 words per dialogue\n",
      "\n",
      "Standard deviation user turns: 3.44 turns per dialogue for user interactions\n",
      "Standard deviation user sentences: 1.22 sentences per dialogue for user interactions\n",
      "Standard deviation user words: 26.33 words per dialogue for user interactions\n",
      "\n",
      "Standard deviation system turns: 3.44 turns per dialogue for system interactions\n",
      "Standard deviation system sentences: 0.95 sentences per dialogue for system interactions\n",
      "Standard deviation system words: 22.22 words per dialogue for system interactions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_total_turns = round(np.std([len(dialogue.split(\"User Turn:\")) for dialogue in dialogues]), 2)\n",
    "std_total_sentences = round(np.std([len(sent_tokenize(dialogue)) for dialogue in dialogues]), 2)\n",
    "std_total_words = round(np.std([len(word_tokenize(dialogue)) for dialogue in dialogues]), 2)\n",
    "\n",
    "std_user_turns = round(np.std([dialogue.count(\"User Turn:\") for dialogue in dialogues]), 2)\n",
    "std_user_sentences = round(np.std([len(sent_tokenize(turn)) for dialogue in dialogues for turn in dialogue.split(\"User Turn:\")]), 2)\n",
    "std_user_words = round(np.std([len(word_tokenize(turn)) for dialogue in dialogues for turn in dialogue.split(\"User Turn:\")]), 2)\n",
    "\n",
    "std_system_turns = round(np.std([dialogue.count(\"System Turn:\") for dialogue in dialogues]), 2)\n",
    "std_system_sentences = round(np.std([len(sent_tokenize(turn)) for dialogue in dialogues for turn in dialogue.split(\"System Turn:\")]), 2)\n",
    "std_system_words = round(np.std([len(word_tokenize(turn)) for dialogue in dialogues for turn in dialogue.split(\"System Turn:\")]), 2)\n",
    "\n",
    "# Print the results with units\n",
    "print(f\"Standard deviation total turns: {std_total_turns} turns per dialogue\")\n",
    "print(f\"Standard deviation total sentences: {std_total_sentences} sentences per dialogue\")\n",
    "print(f\"Standard deviation total words: {std_total_words} words per dialogue\\n\")\n",
    "print(f\"Standard deviation user turns: {std_user_turns} turns per dialogue for user interactions\")\n",
    "print(f\"Standard deviation user sentences: {std_user_sentences} sentences per dialogue for user interactions\")\n",
    "print(f\"Standard deviation user words: {std_user_words} words per dialogue for user interactions\\n\")\n",
    "print(f\"Standard deviation system turns: {std_system_turns} turns per dialogue for system interactions\")\n",
    "print(f\"Standard deviation system sentences: {std_system_sentences} sentences per dialogue for system interactions\")\n",
    "print(f\"Standard deviation system words: {std_system_words} words per dialogue for system interactions\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size for user and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vocabulary size: 16909 words\n",
      "System vocabulary size: 16415 words\n",
      "Total vocabulary size: 21991 words\n"
     ]
    }
   ],
   "source": [
    "def calculate_vocabulary_size(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    freq_dist = FreqDist(filtered_words)\n",
    "    return len(freq_dist)\n",
    "\n",
    "def calculate_total_vocabulary_size(user_texts, system_texts):\n",
    "    total_text = ' '.join(user_texts + system_texts)\n",
    "    total_vocabulary_size = calculate_vocabulary_size(total_text)\n",
    "    return total_vocabulary_size\n",
    "\n",
    "user_texts = []\n",
    "system_texts = []\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    turns = dialogue.split(\"User Turn:\")\n",
    "    user_turns_list = turns[1::2]\n",
    "    system_turns_list = turns[2::2]\n",
    "    user_texts.extend(user_turns_list)\n",
    "    system_texts.extend(system_turns_list)\n",
    "\n",
    "user_vocabulary_size = calculate_total_vocabulary_size(user_texts, [])\n",
    "system_vocabulary_size = calculate_total_vocabulary_size([], system_texts)\n",
    "total_vocabulary_size = calculate_total_vocabulary_size(user_texts, system_texts)\n",
    "\n",
    "print(f\"User vocabulary size: {user_vocabulary_size} words\")\n",
    "print(f\"System vocabulary size: {system_vocabulary_size} words\")\n",
    "print(f\"Total vocabulary size: {total_vocabulary_size} words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
